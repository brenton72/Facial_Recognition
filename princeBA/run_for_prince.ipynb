{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from jupyterthemes import jtplot\n",
    "import random\n",
    "import cv2\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../../fer2013/fer2013.csv')\n",
    "table = data.groupby('emotions').count()[['Usage']]\n",
    "table['Pct'] = table['Usage']/table['Usage'].sum()\n",
    "table['Pct'] = table['Pct'].map(lambda x: round(x, 3)*100)\n",
    "\n",
    "def convert_to_numpy(data):\n",
    "    X = data[:,1]\n",
    "    X = np.asarray([np.asarray(X[i].split(\" \")) for i in range(X.shape[0])])\n",
    "    X = np.asarray([X[i].reshape(48,48).astype(int) for i in range(X.shape[0])])\n",
    "    y = data[:,0]\n",
    "    return (X,y)\n",
    "\n",
    "train = data[data['Usage'] == 'Training']\n",
    "train_X, train_Y = convert_to_numpy(train.values)\n",
    "valid = data[data['Usage'] == 'PrivateTest']\n",
    "valid_X, valid_Y = convert_to_numpy(valid.values)\n",
    "test = data[data['Usage'] == 'PublicTest']\n",
    "test_X, test_Y = convert_to_numpy(test.values)\n",
    "\n",
    "\n",
    "def data_iter(x, y, batch_size):\n",
    "    dataset_size = x.shape[0]\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            break   \n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        yield np.asarray([x[index] for index in batch_indices]) ,np.asarray([y[index] for index in batch_indices])\n",
    "        \n",
    "        \n",
    "def early_stop(val_acc_history, t=2, required_progress=0.001):    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    \n",
    "    if(len(val_acc_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_acc_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if (abs(val_acc_history[index] - val_acc_history[index-1]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is grea-ter \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, optimizer, model, batch_size, num_epochs, criterion, to_Add_Softmax=False, is_inception=False):\n",
    "    losses = []\n",
    "    total_batches = int(train_X.shape[0]/ batch_size)\n",
    "    validation_losses = []\n",
    "    \n",
    "    eval_every = 10\n",
    "    print_every = 10\n",
    "    validate_every = int((eval_every/100)*total_batches)\n",
    "    show_every = int((print_every/100)*total_batches)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        train_data = data_iter(train_X, train_Y, batch_size)\n",
    "        for i, (x,y) in enumerate(train_data):\n",
    "            x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "            y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            if is_inception == True:\n",
    "                outputs = outputs[0]\n",
    "            if to_Add_Softmax == True:\n",
    "                outputs = nn.functional.softmax(outputs)\n",
    "            loss = criterion(outputs, y)\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1)%validate_every == 0:\n",
    "                valid_loss_temp = []\n",
    "                valid_data = data_iter(valid_X, valid_Y, batch_size)\n",
    "                for j, (v_x, v_y) in enumerate(valid_data):\n",
    "                    v_x = Variable(torch.from_numpy(v_x).type(torch.FloatTensor))\n",
    "                    v_y = Variable(torch.from_numpy(v_y).type(torch.LongTensor))\n",
    "                    model.eval()\n",
    "                    val_outputs = model(v_x)\n",
    "                    eval_loss = criterion(val_outputs, v_y)\n",
    "                    valid_loss_temp.append(eval_loss.data[0])\n",
    "                validation_losses.append(np.mean(valid_loss_temp))\n",
    "                stop_training = early_stop(validation_losses, 3)\n",
    "                \n",
    "            if stop_training:\n",
    "                print(\"earily stop triggered\")\n",
    "                break\n",
    "            if (i+1) % show_every == 0:\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Train loss: {4}, Validation loss:{5}'.format(\n",
    "                           epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), np.mean(np.array(validation_losses))))\n",
    "        if stop_training == True:\n",
    "            break\n",
    "            \n",
    "num_labels = 7\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "kernel_size = 3\n",
    "batch_size = 80\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def to_rgb1a(data, w, h):\n",
    "\n",
    "    R, _, _ = data.shape\n",
    "    temp = np.zeros((R, 3, w, h))\n",
    "    \n",
    "    for i in tqdm(range(R)):\n",
    "        im = data[0]\n",
    "        ret = np.empty((3, w, h), dtype=np.uint8)\n",
    "        im = cv2.resize(im.astype(float), (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        ret[0, :, :] =  ret[1, :, :] =  ret[2, :, :] =  im\n",
    "        temp[i] = ret\n",
    "        data = np.delete(data, 0, 0)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "old_train_X = train_X\n",
    "train_X = to_rgb1a(old_train_X, 227, 227)\n",
    "old_valid_X = valid_X\n",
    "valid_X = to_rgb1a(old_valid_X, 227, 227)\n",
    "old_test_X = test_X\n",
    "test_X = to_rgb1a(old_test_X, 227, 227)\n",
    "\n",
    "# ResNet\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 7 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, num_labels)\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, resnet, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)\n",
    "\n",
    "\n",
    "resnet.train(False)\n",
    "test_output = resnet(Variable(torch.from_numpy(test_X).type(torch.FloatTensor)))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "accuracy = sum(pred_y == test_Y)/len(test_Y)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
