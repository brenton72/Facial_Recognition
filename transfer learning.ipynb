{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from jupyterthemes import jtplot\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, log_loss, hinge_loss, accuracy_score\n",
    "import random\n",
    "import cv2\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../../fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35887\n",
      "2304\n",
      "             emotions\n",
      "Usage                \n",
      "PrivateTest      3589\n",
      "PublicTest       3589\n",
      "Training        28709\n",
      "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4953</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5121</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8989</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6077</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4002</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6198</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Usage   Pct\n",
       "emotions             \n",
       "0          4953  13.8\n",
       "1           547   1.5\n",
       "2          5121  14.3\n",
       "3          8989  25.0\n",
       "4          6077  16.9\n",
       "5          4002  11.2\n",
       "6          6198  17.3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data.loc[0, 'pixels'].split(' ')))\n",
    "print(data.groupby('Usage').count()[['emotions']])\n",
    "\n",
    "#Frequency of each label\n",
    "print('0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral')\n",
    "table = data.groupby('emotions').count()[['Usage']]\n",
    "table['Pct'] = table['Usage']/table['Usage'].sum()\n",
    "table['Pct'] = table['Pct'].map(lambda x: round(x, 3)*100)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Converting to numpy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_numpy(data):\n",
    "    X = data[:,1]\n",
    "    X = np.asarray([np.asarray(X[i].split(\" \")) for i in range(X.shape[0])])\n",
    "    X = np.asarray([X[i].reshape(48,48).astype(int) for i in range(X.shape[0])])\n",
    "    y = data[:,0]\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['Usage'] == 'Training']\n",
    "train_X, train_Y = convert_to_numpy(train.values)\n",
    "valid = data[data['Usage'] == 'PrivateTest']\n",
    "valid_X, valid_Y = convert_to_numpy(valid.values)\n",
    "test = data[data['Usage'] == 'PublicTest']\n",
    "test_X, test_Y = convert_to_numpy(test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Function to extract the batches from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iter(x, y, batch_size):\n",
    "    dataset_size = x.shape[0]\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            break   \n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        yield np.asarray([x[index] for index in batch_indices]) ,np.asarray([y[index] for index in batch_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Further data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom the image and convert 1 channel to 3 channel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb1a(data, w, h):\n",
    "\n",
    "    R, _, _ = data.shape\n",
    "    temp = np.zeros((R, 3, w, h))\n",
    "    \n",
    "    for i in tqdm(range(R)):\n",
    "        im = data[0]\n",
    "        ret = np.empty((3, w, h), dtype=np.uint8)\n",
    "        im = cv2.resize(im.astype(float), (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        ret[0, :, :] =  ret[1, :, :] =  ret[2, :, :] =  im\n",
    "        temp[i] = ret\n",
    "        data = np.delete(data, 0, 0)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training stage setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def early_stop(val_acc_history, t=2, required_progress=0.001):    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    \n",
    "    if(len(val_acc_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_acc_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if (abs(val_acc_history[index] - val_acc_history[index-1]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is grea-ter \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, optimizer, model, batch_size, num_epochs, criterion, to_Add_Softmax=False, is_inception=False):\n",
    "    losses = []\n",
    "    total_batches = int(train_X.shape[0]/ batch_size)\n",
    "    validation_losses = []\n",
    "    \n",
    "    eval_every = 10\n",
    "    print_every = 10\n",
    "    validate_every = int((eval_every/100)*total_batches)\n",
    "    show_every = int((print_every/100)*total_batches)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        train_data = data_iter(train_X, train_Y, batch_size)\n",
    "        for i, (x,y) in enumerate(train_data):\n",
    "            x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "            y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            if is_inception == True:\n",
    "                outputs = outputs[0]\n",
    "            if to_Add_Softmax == True:\n",
    "                outputs = nn.functional.softmax(outputs)\n",
    "            loss = criterion(outputs, y)\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1)%validate_every == 0:\n",
    "                valid_loss_temp = []\n",
    "                valid_data = data_iter(valid_X, valid_Y, batch_size)\n",
    "                for j, (v_x, v_y) in enumerate(valid_data):\n",
    "                    v_x = Variable(torch.from_numpy(v_x).type(torch.FloatTensor))\n",
    "                    v_y = Variable(torch.from_numpy(v_y).type(torch.LongTensor))\n",
    "                    model.eval()\n",
    "                    val_outputs = model(v_x)\n",
    "                    eval_loss = criterion(val_outputs, v_y)\n",
    "                    valid_loss_temp.append(eval_loss.data[0])\n",
    "                validation_losses.append(np.mean(valid_loss_temp))\n",
    "                stop_training = early_stop(validation_losses, 3)\n",
    "                \n",
    "            if stop_training:\n",
    "                print(\"earily stop triggered\")\n",
    "                break\n",
    "            if (i+1) % show_every == 0:\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Train loss: {4}, Validation loss:{5}'.format(\n",
    "                           epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), np.mean(np.array(validation_losses))))\n",
    "        if stop_training == True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Removing last layer & extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_last_layer(model):\n",
    "    mod = list(model.classifier.children())\n",
    "    mod.pop()\n",
    "    new_classifier = torch.nn.Sequential(*mod)\n",
    "    model.classifier = new_classifier\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(data, model):\n",
    "    model = remove_last_layer(model)\n",
    "    return model(Variable(torch.from_numpy(data).type(torch.FloatTensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with a smaller dataset (as running imagenet architectures locally is very time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 207.86it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 341.54it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 357.26it/s]\n"
     ]
    }
   ],
   "source": [
    "old_train_X = train_X\n",
    "train_X = to_rgb1a(old_train_X[0:1000], 227, 227)\n",
    "old_valid_X = valid_X\n",
    "valid_X = to_rgb1a(old_valid_X[0:500], 227, 227)\n",
    "old_test_X = test_X\n",
    "test_X = to_rgb1a(old_test_X[0:500], 227, 227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1) Only ImageNet Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) first model - VGG (Note that VGG is the very slow among everyone else) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_labels = 7\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "kernel_size = 3\n",
    "batch_size = 80\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "vgg = models.vgg16(pretrained=True)\n",
    "num_ftrs = vgg.classifier\n",
    "\n",
    "## Modifying and training only the last layer\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg.classifier._modules['6'] = nn.Linear(4096, num_labels)\n",
    "for param in vgg.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "optimizer = optim.Adam(vgg.classifier[6].parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, vgg, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Step: [1/12], Train loss: 0.1632013519605001, Validation loss:11.684929211934408\n",
      "Epoch: [1/1], Step: [2/12], Train loss: 0.1643969863653183, Validation loss:11.655517816543579\n",
      "Epoch: [1/1], Step: [3/12], Train loss: 0.1654719743463728, Validation loss:11.722200711568197\n",
      "Epoch: [1/1], Step: [4/12], Train loss: 0.16535725692907968, Validation loss:11.647497693697611\n",
      "Epoch: [1/1], Step: [5/12], Train loss: 0.16612525383631388, Validation loss:11.563029861450195\n",
      "Epoch: [1/1], Step: [6/12], Train loss: 0.16569271352556017, Validation loss:11.443655490875244\n",
      "Epoch: [1/1], Step: [7/12], Train loss: 0.16496338163103377, Validation loss:11.379524321783157\n",
      "Epoch: [1/1], Step: [8/12], Train loss: 0.1645751123627027, Validation loss:11.320532818635304\n",
      "Epoch: [1/1], Step: [9/12], Train loss: 0.16432406725706877, Validation loss:11.249501228332518\n",
      "Epoch: [1/1], Step: [10/12], Train loss: 0.1649247646331787, Validation loss:11.187508185704548\n",
      "Epoch: [1/1], Step: [11/12], Train loss: 0.16468113299572107, Validation loss:11.147463263887346\n",
      "Epoch: [1/1], Step: [12/12], Train loss: 0.164430288804902, Validation loss:11.116020335091484\n"
     ]
    }
   ],
   "source": [
    "### Still some modification needs to be made\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "num_ftrs = alexnet.classifier\n",
    "\n",
    "## Modifying and training only the last layer\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexnet.classifier._modules['6'] = nn.Linear(4096, num_labels)\n",
    "# num_ftrs = alexnet.classifier[6].in_features\n",
    "# alexnet.classifier[6].out_features = num_labels\n",
    "for param in alexnet.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, alexnet.parameters()), alexnet.classifier.parameters())\n",
    "optimizer = optim.Adam(alexnet.classifier[6].parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, alexnet, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Step: [1/12], Train loss: 0.16207279761632284, Validation loss:3.240700642267863\n",
      "Epoch: [1/1], Step: [2/12], Train loss: 0.1620688041051229, Validation loss:2.753064215183258\n",
      "Epoch: [1/1], Step: [3/12], Train loss: 0.16196048922008938, Validation loss:2.516954706774818\n",
      "Epoch: [1/1], Step: [4/12], Train loss: 0.16179496298233667, Validation loss:2.3845895628134413\n",
      "Epoch: [1/1], Step: [5/12], Train loss: 0.16150825421015422, Validation loss:2.296902922789256\n",
      "Epoch: [1/1], Step: [6/12], Train loss: 0.16132187015480465, Validation loss:2.233507063653734\n",
      "Epoch: [1/1], Step: [7/12], Train loss: 0.16137162418592543, Validation loss:2.1852992177009587\n",
      "Epoch: [1/1], Step: [8/12], Train loss: 0.16126281271378198, Validation loss:2.1471483260393143\n",
      "Epoch: [1/1], Step: [9/12], Train loss: 0.16128376567805255, Validation loss:2.117350732838666\n",
      "Epoch: [1/1], Step: [10/12], Train loss: 0.16130946079889932, Validation loss:2.09268914659818\n",
      "Epoch: [1/1], Step: [11/12], Train loss: 0.16119460987322257, Validation loss:2.073133367480654\n",
      "Epoch: [1/1], Step: [12/12], Train loss: 0.16108966867129007, Validation loss:2.0566602829429836\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 7 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, num_labels)\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, resnet, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception requires input size to be (299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 207.59it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 289.15it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 302.43it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = to_rgb1a(old_train_X[0:1000], 299, 299)\n",
    "valid_X = to_rgb1a(old_valid_X[0:500], 299, 299)\n",
    "test_X = to_rgb1a(old_test_X[0:500], 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incptn = models.inception_v3(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in incptn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 7 classes\n",
    "num_ftrs = incptn.fc.in_features\n",
    "incptn.fc = torch.nn.Linear(num_ftrs, num_labels)\n",
    "optimizer = optim.Adam(incptn.fc.parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, incptn, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) Ensemble of ImageNet and LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_class_accuracy(pred, true):\n",
    "    return sum(pred == true)/pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Alexnet + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.232\n"
     ]
    }
   ],
   "source": [
    "# get features for train, valid and test data\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "features_train = extract_features(train_X, alexnet)\n",
    "features_train = np.array(features_train.data)\n",
    "features_valid = extract_features(valid_X, alexnet)\n",
    "features_valid = np.array(features_valid.data)\n",
    "features_test = extract_features(test_X, alexnet)\n",
    "features_test = np.array(features_test.data)\n",
    "\n",
    "# Use both train and validation for training SVM\n",
    "features_train = np.concatenate((features_train, features_valid))\n",
    "train_Y = np.concatenate((train_Y[:1000], valid_Y[:500]))\n",
    "\n",
    "# Use sklearn for svm\n",
    "clf = svm.SVC(C=2, kernel='rbf', decision_function_shape='ovr')\n",
    "clf.fit(features_train, train_Y.astype(int))\n",
    "\n",
    "# Prediction on test set\n",
    "pred_y = clf.predict(features_test)\n",
    "test_accuracy = multi_class_accuracy(pred_y, test_Y[:500])\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Calculating accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.156\n"
     ]
    }
   ],
   "source": [
    "#test_output = model(Variable(torch.from_numpy(test_X).type(torch.FloatTensor)))\n",
    "resnet.train(False)\n",
    "test_output = resnet(Variable(torch.from_numpy(test_X).type(torch.FloatTensor)))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "accuracy = sum(pred_y == test_Y[0:500])/len(test_Y[0:500])\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
