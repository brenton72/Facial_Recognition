{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from jupyterthemes import jtplot\n",
    "import random\n",
    "import cv2\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../../fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35887\n",
      "2304\n",
      "             emotions\n",
      "Usage                \n",
      "PrivateTest      3589\n",
      "PublicTest       3589\n",
      "Training        28709\n",
      "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4953</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>547</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5121</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8989</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6077</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4002</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6198</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Usage   Pct\n",
       "emotions             \n",
       "0          4953  13.8\n",
       "1           547   1.5\n",
       "2          5121  14.3\n",
       "3          8989  25.0\n",
       "4          6077  16.9\n",
       "5          4002  11.2\n",
       "6          6198  17.3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data.loc[0, 'pixels'].split(' ')))\n",
    "print(data.groupby('Usage').count()[['emotions']])\n",
    "\n",
    "#Frequency of each label\n",
    "print('0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral')\n",
    "table = data.groupby('emotions').count()[['Usage']]\n",
    "table['Pct'] = table['Usage']/table['Usage'].sum()\n",
    "table['Pct'] = table['Pct'].map(lambda x: round(x, 3)*100)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Converting to numpy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_numpy(data):\n",
    "    X = data[:,1]\n",
    "    X = np.asarray([np.asarray(X[i].split(\" \")) for i in range(X.shape[0])])\n",
    "    X = np.asarray([X[i].reshape(48,48).astype(int) for i in range(X.shape[0])])\n",
    "    y = data[:,0]\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['Usage'] == 'Training']\n",
    "train_X, train_Y = convert_to_numpy(train.values)\n",
    "valid = data[data['Usage'] == 'PrivateTest']\n",
    "valid_X, valid_Y = convert_to_numpy(valid.values)\n",
    "test = data[data['Usage'] == 'PublicTest']\n",
    "test_X, test_Y = convert_to_numpy(test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Function to extract the batches from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_iter(x, y, batch_size):\n",
    "    dataset_size = x.shape[0]\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            break   \n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        yield np.asarray([x[index] for index in batch_indices]) ,np.asarray([y[index] for index in batch_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) First implementation (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN model\n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self, kernel_size, num_labels, n_layers=1, dropout=0.1):\n",
    "       \n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(1, 10, kernel_size=kernel_size, stride=1, padding=1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(kernel_size=2),\n",
    "                            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                            nn.Conv2d(10, 20, kernel_size=kernel_size, stride=1, padding=1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(kernel_size=2),\n",
    "                            )\n",
    "        self.out = nn.Linear(20*12*12, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) # (N,Ci,W,D)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) # Note that normally ppl dont use dropout in CNN\n",
    "        x = self.out(x)\n",
    "        return torch.nn.functional.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training stage setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def early_stop(val_acc_history, t=2, required_progress=0.001):    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    \n",
    "    if(len(val_acc_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_acc_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if (abs(val_acc_history[index] - val_acc_history[index-1]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is grea-ter \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, optimizer, model, batch_size, num_epochs, criterion, to_Add_Softmax=False, is_inception=False):\n",
    "    losses = []\n",
    "    total_batches = int(train_X.shape[0]/ batch_size)\n",
    "    validation_losses = []\n",
    "    \n",
    "    eval_every = 10\n",
    "    print_every = 10\n",
    "    validate_every = int((eval_every/100)*total_batches)\n",
    "    show_every = int((print_every/100)*total_batches)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        train_data = data_iter(train_X, train_Y, batch_size)\n",
    "        for i, (x,y) in enumerate(train_data):\n",
    "            x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "            y = Variable(torch.from_numpy(y).type(torch.LongTensor))\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            if is_inception == True:\n",
    "                outputs = outputs[0]\n",
    "            if to_Add_Softmax == True:\n",
    "                outputs = nn.functional.softmax(outputs)\n",
    "            loss = criterion(outputs, y)\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1)%validate_every == 0:\n",
    "                valid_loss_temp = []\n",
    "                valid_data = data_iter(valid_X, valid_Y, batch_size)\n",
    "                for j, (v_x, v_y) in enumerate(valid_data):\n",
    "                    v_x = Variable(torch.from_numpy(v_x).type(torch.FloatTensor))\n",
    "                    v_y = Variable(torch.from_numpy(v_y).type(torch.LongTensor))\n",
    "                    model.eval()\n",
    "                    val_outputs = model(v_x)\n",
    "                    eval_loss = criterion(val_outputs, v_y)\n",
    "                    valid_loss_temp.append(eval_loss.data[0])\n",
    "                validation_losses.append(np.mean(valid_loss_temp))\n",
    "                stop_training = early_stop(validation_losses, 3)\n",
    "                \n",
    "            if stop_training:\n",
    "                print(\"earily stop triggered\")\n",
    "                break\n",
    "            if (i+1) % show_every == 0:\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Train loss: {4}, Validation loss:{5}'.format(\n",
    "                           epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), np.mean(np.array(validation_losses))))\n",
    "        if stop_training == True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_weights(train_Y, valid_Y, test_Y):\n",
    "    \n",
    "    from scipy.stats import itemfreq as freq\n",
    "    Y = np.concatenate((train_Y, valid_Y, test_Y))\n",
    "    weight = freq(Y)[:, 1]\n",
    "    weight = 1/weight*len(Y)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [35/358], Train loss: -0.0019272052042977105, Validation loss:-0.6499483023177494\n",
      "Epoch: [1/5], Step: [70/358], Train loss: -0.0019362375389930257, Validation loss:-0.6535193544219841\n",
      "Epoch: [1/5], Step: [105/358], Train loss: -0.0019157088708294044, Validation loss:-0.6530159840529616\n",
      "Epoch: [1/5], Step: [140/358], Train loss: -0.0019162179282305248, Validation loss:-0.6544163341379978\n",
      "Epoch: [1/5], Step: [175/358], Train loss: -0.0018970537965809547, Validation loss:-0.6547612467272714\n",
      "Epoch: [1/5], Step: [210/358], Train loss: -0.0019042137190679756, Validation loss:-0.6550600633138056\n",
      "Epoch: [1/5], Step: [245/358], Train loss: -0.0019066129340615543, Validation loss:-0.6536110183345033\n",
      "Epoch: [1/5], Step: [280/358], Train loss: -0.0019117102463984622, Validation loss:-0.6536332568238404\n",
      "Epoch: [1/5], Step: [315/358], Train loss: -0.0019232594518677566, Validation loss:-0.6525290673504575\n",
      "Epoch: [1/5], Step: [350/358], Train loss: -0.0019231603993288726, Validation loss:-0.6529129299589178\n",
      "Epoch: [2/5], Step: [35/358], Train loss: -0.0009607869869546259, Validation loss:-0.6539747835375553\n",
      "Epoch: [2/5], Step: [70/358], Train loss: -0.0009644863980093905, Validation loss:-0.6540724364476221\n",
      "Epoch: [2/5], Step: [105/358], Train loss: -0.0009667926600230629, Validation loss:-0.6545017073777589\n",
      "Epoch: [2/5], Step: [140/358], Train loss: -0.000964147394248837, Validation loss:-0.6543311580967206\n",
      "Epoch: [2/5], Step: [175/358], Train loss: -0.0009621732104127865, Validation loss:-0.6539228397111098\n",
      "Epoch: [2/5], Step: [210/358], Train loss: -0.0009636217229216598, Validation loss:-0.6539453100624748\n",
      "Epoch: [2/5], Step: [245/358], Train loss: -0.0009611129587622163, Validation loss:-0.6534731672767968\n",
      "Epoch: [2/5], Step: [280/358], Train loss: -0.0009630002598489359, Validation loss:-0.6535408964775729\n",
      "Epoch: [2/5], Step: [315/358], Train loss: -0.0009610909494770095, Validation loss:-0.6541066267594481\n",
      "Epoch: [2/5], Step: [350/358], Train loss: -0.0009614504384972119, Validation loss:-0.6540332789956169\n",
      "Epoch: [3/5], Step: [35/358], Train loss: -0.0006405170277677877, Validation loss:-0.6542468291114678\n",
      "Epoch: [3/5], Step: [70/358], Train loss: -0.0006391555988426698, Validation loss:-0.6539940029105619\n",
      "Epoch: [3/5], Step: [105/358], Train loss: -0.0006385140378142116, Validation loss:-0.6540940542495534\n",
      "Epoch: [3/5], Step: [140/358], Train loss: -0.0006391022595351952, Validation loss:-0.6540095443047131\n",
      "Epoch: [3/5], Step: [175/358], Train loss: -0.0006393747559394354, Validation loss:-0.6538950869847427\n",
      "Epoch: [3/5], Step: [210/358], Train loss: -0.000639332659803658, Validation loss:-0.6536969416546863\n",
      "Epoch: [3/5], Step: [245/358], Train loss: -0.000640177598794574, Validation loss:-0.6539313286066255\n",
      "Epoch: [3/5], Step: [280/358], Train loss: -0.0006408535241494507, Validation loss:-0.6538496162718186\n",
      "Epoch: [3/5], Step: [315/358], Train loss: -0.0006407826958734743, Validation loss:-0.653804429611162\n",
      "Epoch: [3/5], Step: [350/358], Train loss: -0.0006408513524324813, Validation loss:-0.6534320066259666\n",
      "Epoch: [4/5], Step: [35/358], Train loss: -0.0004804687406482942, Validation loss:-0.6532890033359228\n",
      "Epoch: [4/5], Step: [70/358], Train loss: -0.0004811643101395762, Validation loss:-0.6532935766312717\n",
      "Epoch: [4/5], Step: [105/358], Train loss: -0.00048106377830362614, Validation loss:-0.653393483369229\n",
      "Epoch: [4/5], Step: [140/358], Train loss: -0.000481365304841579, Validation loss:-0.6534311781154278\n",
      "Epoch: [4/5], Step: [175/358], Train loss: -0.0004809471621438441, Validation loss:-0.6534106403395727\n",
      "Epoch: [4/5], Step: [210/358], Train loss: -0.00048104813417244446, Validation loss:-0.6534533246674321\n",
      "Epoch: [4/5], Step: [245/358], Train loss: -0.00048081984112979906, Validation loss:-0.6536938459486574\n",
      "Epoch: [4/5], Step: [280/358], Train loss: -0.0004812091344490583, Validation loss:-0.65346942957865\n",
      "Epoch: [4/5], Step: [315/358], Train loss: -0.0004811365578828492, Validation loss:-0.6537001100314525\n",
      "Epoch: [4/5], Step: [350/358], Train loss: -0.000481315402225325, Validation loss:-0.6536096180535176\n",
      "Epoch: [5/5], Step: [35/358], Train loss: -0.000384927937500562, Validation loss:-0.6536452151058518\n",
      "Epoch: [5/5], Step: [70/358], Train loss: -0.0003852121294804444, Validation loss:-0.6537550064005377\n",
      "Epoch: [5/5], Step: [105/358], Train loss: -0.00038531849192427714, Validation loss:-0.6537448019419362\n",
      "Epoch: [5/5], Step: [140/358], Train loss: -0.00038481934455818196, Validation loss:-0.6537086035255805\n",
      "Epoch: [5/5], Step: [175/358], Train loss: -0.0003849611464635617, Validation loss:-0.6536638131797916\n",
      "Epoch: [5/5], Step: [210/358], Train loss: -0.0003848292271035526, Validation loss:-0.653635251059716\n",
      "Epoch: [5/5], Step: [245/358], Train loss: -0.0003848275608965793, Validation loss:-0.6537213710567247\n",
      "Epoch: [5/5], Step: [280/358], Train loss: -0.0003850240353917924, Validation loss:-0.6538013445326324\n",
      "Epoch: [5/5], Step: [315/358], Train loss: -0.0003850668388176466, Validation loss:-0.6536857519015421\n",
      "Epoch: [5/5], Step: [350/358], Train loss: -0.0003848966647238191, Validation loss:-0.6537793031538074\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "kernel_size = 3\n",
    "batch_size = 80\n",
    "\n",
    "model = CNN( kernel_size, num_labels, n_layers=1, dropout=0.1)\n",
    "weights = calculate_weights(train_Y, valid_Y, test_Y)\n",
    "weights = torch.FloatTensor(weights)\n",
    "criterion = nn.NLLLoss(weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, model, batch_size, num_epochs, criterion, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14687500000000001, array([[  4,  16, 322,   4,   1,  11, 101],\n",
       "        [  0,   3,  40,   0,   0,   2,  11],\n",
       "        [  2,  13, 338,   3,   0,  15, 118],\n",
       "        [  4,  45, 636,   3,   1,  28, 162],\n",
       "        [  4,  24, 462,   7,   0,  15, 128],\n",
       "        [  3,  14, 294,   0,   0,   5,  90],\n",
       "        [  3,  43, 350,   8,   0,  23, 164]], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_on_subset(model, X, Y, batch_size):\n",
    "    iter_data = data_iter(X, Y, batch_size)\n",
    "    total_batches = int(X.shape[0]/ batch_size)\n",
    "    accuracy_list = []\n",
    "    pred_output = []\n",
    "    true_output = []\n",
    "\n",
    "    for i, (x,y) in enumerate(iter_data):\n",
    "        x = Variable(torch.from_numpy(x).type(torch.FloatTensor))\n",
    "        test_output = model(x).type(torch.FloatTensor)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "        accuracy = sum(pred_y == y)/len(y)\n",
    "        accuracy_list.append(accuracy)\n",
    "        pred_output.extend(pred_y)\n",
    "        true_output.extend(y)\n",
    "    return np.mean(accuracy_list), confusion_matrix(true_output, pred_output)\n",
    "\n",
    "get_accuracy_on_subset(model, test_X, test_Y, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) Zoom the image and convert 1 channel to 3 channel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_rgb1a(data, w, h):\n",
    "\n",
    "    R, _, _ = data.shape\n",
    "    temp = np.zeros((R, 3, w, h))\n",
    "    \n",
    "    for i in tqdm(range(R)):\n",
    "        im = data[0]\n",
    "        ret = np.empty((3, w, h), dtype=np.uint8)\n",
    "        im = cv2.resize(im.astype(float), (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        ret[0, :, :] =  ret[1, :, :] =  ret[2, :, :] =  im\n",
    "        temp[i] = ret\n",
    "        data = np.delete(data, 0, 0)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with a smaller dataset (as running imagenet architectures locally is very time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 243.69it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 487.80it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 485.77it/s]\n"
     ]
    }
   ],
   "source": [
    "old_train_X = train_X\n",
    "train_X = to_rgb1a(old_train_X[0:1000], 227, 227)\n",
    "old_valid_X = valid_X\n",
    "valid_X = to_rgb1a(old_valid_X[0:500], 227, 227)\n",
    "old_test_X = test_X\n",
    "test_X = to_rgb1a(old_test_X[0:500], 227, 227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Using the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-2b8090aae138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malexnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_Add_Softmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-5535d50cf879>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_X, train_Y, valid_X, valid_Y, optimizer, model, batch_size, num_epochs, criterion, to_Add_Softmax, is_inception)\u001b[0m\n\u001b[0;32m     55\u001b[0m                     \u001b[0mv_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                     \u001b[0mval_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                     \u001b[0meval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mvalid_loss_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torchvision-0.1.8-py3.5.egg\\torchvision\\models\\alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Still some modification needs to be made\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "num_ftrs = alexnet.classifier\n",
    "\n",
    "## Modifying and training only the last layer\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "alexnet.classifier._modules['6'] = nn.Linear(4096, num_labels)\n",
    "# num_ftrs = alexnet.classifier[6].in_features\n",
    "# alexnet.classifier[6].out_features = num_labels\n",
    "for param in alexnet.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in alexnet.classifier[5].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "params = filter(lambda p: p.requires_grad, alexnet.parameters())\n",
    "    \n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, alexnet.parameters()), alexnet.classifier.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, alexnet, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.layer4[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 7 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, num_labels)\n",
    "\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in resnet.layer4[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "params = filter(lambda p: p.requires_grad, resnet.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, resnet, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception requires input size to be (299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 257.78it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 396.00it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 407.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = to_rgb1a(old_train_X[0:1000], 299, 299)\n",
    "valid_X = to_rgb1a(old_valid_X[0:500], 299, 299)\n",
    "test_X = to_rgb1a(old_test_X[0:500], 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incptn = models.inception_v3(pretrained=True)\n",
    "# freeze all model parameters\n",
    "for param in incptn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 7 classes\n",
    "num_ftrs = incptn.fc.in_features\n",
    "incptn.fc = torch.nn.Linear(num_ftrs, num_labels)\n",
    "\n",
    "for param in incptn.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in incptn.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "params = filter(lambda p: p.requires_grad, incptn.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "train(train_X, train_Y, valid_X, valid_Y, optimizer, incptn, batch_size, num_epochs, criterion, to_Add_Softmax=True, is_inception=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Calculating accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.156\n"
     ]
    }
   ],
   "source": [
    "#test_output = model(Variable(torch.from_numpy(test_X).type(torch.FloatTensor)))\n",
    "resnet.train(False)\n",
    "test_output = resnet(Variable(torch.from_numpy(test_X).type(torch.FloatTensor)))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "accuracy = sum(pred_y == test_Y[0:500])/len(test_Y[0:500])\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
